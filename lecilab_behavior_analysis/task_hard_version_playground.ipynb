{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import lecilab_behavior_analysis.utils as utils\n",
    "import lecilab_behavior_analysis.plots as plots\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import lecilab_behavior_analysis.df_transforms as dft\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import seaborn as sns\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "single mouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from cluster\n",
    "tv_projects = utils.get_server_projects()\n",
    "print(tv_projects)\n",
    "# see the available animals\n",
    "animals = utils.get_animals_in_project(tv_projects[1])\n",
    "print(animals)\n",
    "# download the data for a specific animal\n",
    "mouse = \"ACV007\"\n",
    "local_path = Path(utils.get_outpath()) / Path(tv_projects[1]) / Path(\"sessions\") / Path(mouse)\n",
    "# create the directory if it doesn't exist\n",
    "local_path.mkdir(parents=True, exist_ok=True)\n",
    "# download the session data\n",
    "utils.rsync_session_data(\n",
    "    project_name=tv_projects[1],\n",
    "    animal=mouse,\n",
    "    local_path=str(local_path),\n",
    "    credentials=utils.get_idibaps_cluster_credentials(),\n",
    ")\n",
    "# load the data\n",
    "df = pd.read_csv(local_path / Path(f'{mouse}.csv'), sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce the dataset to the psychometric version of the task\n",
    "# Otherwise, we would include a lot of \"easy\" trials that would bias the fit\n",
    "df_test = df[df[\"current_training_stage\"] == \"TwoAFC_visual_hard\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "psychometric curve "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = dft.get_performance_by_difficulty_ratio(df_test)\n",
    "plots.psychometric_plot(df_test, x = 'visual_stimulus_ratio', y = 'left_choice')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example plot with log-scaled y-axis\n",
    "sns.pointplot(\n",
    "    x='visual_stimulus_ratio',\n",
    "    y='left_choice',\n",
    "    data=df_test,\n",
    "    estimator=lambda x: np.log(np.mean(x) / (1 - np.mean(x))),  # Log odds transformation\n",
    "    color='blue',\n",
    "    markers='o',\n",
    "    errorbar=(\"ci\", 95),\n",
    "    native_scale=True,\n",
    "    linestyles='',\n",
    ")\n",
    "\n",
    "X = df_test['visual_stimulus_ratio'].unique()\n",
    "log_odds = []\n",
    "for x in X:\n",
    "    p = df_test[df_test['visual_stimulus_ratio'] == x]['left_choice'].mean()\n",
    "    log_odds.append(np.log(p / (1 - p)))\n",
    "\n",
    "# fit a simple line to the points\n",
    "model = np.polyfit(X, log_odds, 1)\n",
    "xs = np.linspace(df_test['visual_stimulus_ratio'].min(), df_test['visual_stimulus_ratio'].max(), 100).reshape(-1, 1)\n",
    "predicted_log_odds = model[0] * xs + model[1]\n",
    "\n",
    "plt.plot(xs, predicted_log_odds, color='red', label='Predicted Log Odds')\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel(\"Visual Stimulus Ratio\")\n",
    "plt.ylabel(\"Log Odds of Left Choice\")\n",
    "plt.title(\"Psychometric Curve with Log Odds\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GLM comparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.column_checker(df_test, required_columns={x for x in parameters_for_fit})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "parameters_for_fit = ['visual_stimulus_ratio',\n",
    "                      'previous_port_before_stimulus_numeric',\n",
    "                      'interaction_term',\n",
    "                      'previous_choice_left_correct',\n",
    "                      'previous_choice_right_wrong',\n",
    "                      'previous_choice_left', \n",
    "                      'interaction_term_brightness'\n",
    "                    ]\n",
    "variable_for_prediction = 'left_choice'\n",
    "\n",
    "# drop NaN values if any\n",
    "df_for_fit = df_test.dropna(subset=parameters_for_fit + [variable_for_prediction])\n",
    "df_for_fit = df_for_fit[parameters_for_fit].astype(int)\n",
    "\n",
    "# Prepare the independent variables\n",
    "X_multi = df_for_fit[parameters_for_fit].values\n",
    "X_multi_const = sm.add_constant(X_multi)\n",
    "y = df_for_fit[variable_for_prediction].values.astype(int)\n",
    "\n",
    "# Fit the logistic regression model with multiple regressors\n",
    "logit_model_multi = sm.Logit(y, X_multi_const).fit()\n",
    "\n",
    "# Display the summary, which includes p-values for all regressors\n",
    "print(logit_model_multi.summary(xname= [\"intercept\"] + parameters_for_fit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the [] of parameters_for_fit\n",
    "parameters_ = [f\"'{param}'\" for param in parameters_for_fit]\n",
    "parameters_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate the \"evidences\" and the choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['visual_stimulus_ratio'] = df_test['visual_stimulus'].apply(lambda x: abs(eval(x)[0] / eval(x)[1]))\n",
    "# transform it to a log value, preserving the negative sign\n",
    "df_test['visual_stimulus_ratio'] = df_test['visual_stimulus_ratio'].apply(lambda x: np.log(x))\n",
    "# reduce the decimal places to 4, so it is easier to read\n",
    "df_test['visual_stimulus_ratio'] = df_test['visual_stimulus_ratio'].apply(lambda x: round(x, 4))\n",
    "# This was good in order to make the fit work for both left and right choices!\n",
    "df_test['visual_stimulus_ratio'] = df_test.apply(\n",
    "    lambda row: row['visual_stimulus_ratio'] if row['correct_side'] == 'left' else -row['visual_stimulus_ratio'],\n",
    "    axis=1\n",
    ")\n",
    "df_test['visual_stimulus_diff'] = df_test['visual_stimulus'].apply(lambda x: abs(eval(x)[0] - eval(x)[1]))\n",
    "df_test['visual_stimulus_diff'] = df_test.apply(\n",
    "    lambda row: row['visual_stimulus_diff'] if row['correct_side'] == 'left' else -row['visual_stimulus_diff'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# !!!!! This introduces a bug!! What would happen on the trials where the mouse has to go right? Which value would be used then?\n",
    "# df_test['left_choice'] = np.where((df_test['correct_side'] == 'left') & (df_test['correct'] == True), 1, 0)\n",
    "\n",
    "# What you want is a value that goes from 0 to 1, indicating the probability of a left choice.\n",
    "# For this fits, we really don't care about the correct side, we just want to know if the mouse chose left or right.\n",
    "\n",
    "# I realized that the way I was plotting this before was using the performance of the mouse and the trials difficulty,\n",
    "# in order to infer back the probability of a left choice. But we can actually use something simpler and less confusing:\n",
    "\n",
    "# I had already created a function in the df_transforms module, to get the first choice of a mouse so we can use it here\n",
    "df_test = dft.add_mouse_first_choice(df_test)\n",
    "# This creates the column \"first_choice\" that indicates \"left\" or \"right\" for each trial.\n",
    "\n",
    "# Now we can transform this to 0 and 1, where 0 is right and 1 is left\n",
    "df_test['left_choice'] = df_test['first_choice'].apply(lambda x: 1 if x == 'left' else 0)\n",
    "\n",
    "# By the way I am naming columns weirdly, just so you can play around with the different solutions and see how they work.\n",
    "# Once we have what we need, we should clean up the code and use more meaningful names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_evidence_ratio(df):\n",
    "    df['visual_stimulus_ratio'] = df['visual_stimulus'].apply(lambda x: abs(eval(x)[0] / eval(x)[1]))\n",
    "    # transform it to a log value, preserving the negative sign\n",
    "    df['visual_stimulus_ratio'] = df['visual_stimulus_ratio'].apply(lambda x: np.log(x))\n",
    "    # reduce the decimal places to 4, so it is easier to read\n",
    "    df['visual_stimulus_ratio'] = df['visual_stimulus_ratio'].apply(lambda x: round(x, 4))\n",
    "    # This was good in order to make the fit work for both left and right choices!\n",
    "    df['visual_stimulus_ratio'] = df.apply(\n",
    "        lambda row: row['visual_stimulus_ratio'] if row['correct_side'] == 'left' else -row['visual_stimulus_ratio'],\n",
    "        axis=1\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def get_left_choice(df):\n",
    "    df = dft.add_mouse_first_choice(df)\n",
    "    df['left_choice'] = df['first_choice'].apply(lambda x: 1 if x == 'left' else 0)\n",
    "    return df\n",
    "\n",
    "df_test = get_evidence_ratio(df_test)\n",
    "df_test = get_left_choice(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can fit the data and visualize the results\n",
    "X = df_test['visual_stimulus_ratio'].values.reshape(-1, 1)\n",
    "y = df_test['left_choice'].values.astype(int)\n",
    "model = LogisticRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Now we have a model that predicts the probability of a left choice based on ANY visual stimulus ratio (xs).\n",
    "# For plotting, we can generate a range of values for the visual stimulus ratio\n",
    "import numpy as np\n",
    "xs = np.linspace(df_test['visual_stimulus_ratio'].min(), df_test['visual_stimulus_ratio'].max(), 100).reshape(-1, 1)\n",
    "y_prob = model.predict_proba(xs)[:, 1]\n",
    "\n",
    "# Plot the actual choices of the mouse\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "sns.pointplot(\n",
    "    x='visual_stimulus_ratio',\n",
    "    y='left_choice',\n",
    "    data=df_test,\n",
    "    estimator=lambda x: np.mean(x),\n",
    "    color='blue',\n",
    "    markers='o',\n",
    "    errorbar=(\"ci\", 95),\n",
    "    ax=ax,\n",
    "    label='Observed Choices',\n",
    "    native_scale= True,\n",
    "    linestyles='',\n",
    ")\n",
    "\n",
    "# overlay the fitted logistic regression curve\n",
    "ax.plot(xs, y_prob, color='red', label='Logistic Regression Fit')\n",
    "ax.set_xlabel(\"Visual Stimulus ratio\")\n",
    "ax.set_ylabel(\"Probability of Left Choice\")\n",
    "ax.set_ylim(0, 1)\n",
    "plt.title(\"Psychometric Curve\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing a model with lapses\n",
    "from scipy.optimize import minimize\n",
    "import numpy as np\n",
    "\n",
    "# Define the lapse logistic function with independent lapses for left and right\n",
    "def lapse_logistic_independent(params, x, y):\n",
    "    lapse_left, lapse_right, beta, x0 = params\n",
    "    # Ensure lapse rates are within [0, 0.5]\n",
    "    lapse_left = np.clip(lapse_left, 0, 0.5)\n",
    "    lapse_right = np.clip(lapse_right, 0, 0.5)\n",
    "    # Predicted probabilities\n",
    "    p_left = lapse_left + (1 - lapse_left - lapse_right) / (1 + np.exp(-beta * (x - x0)))\n",
    "    # Negative log-likelihood\n",
    "    nll = -np.sum(y * np.log(p_left) + (1 - y) * np.log(1 - p_left))\n",
    "    return nll\n",
    "\n",
    "# Initial parameter guesses: [lapse_left, lapse_right, beta, x0]\n",
    "initial_params = [0.05, 0.05, 1, 0]\n",
    "\n",
    "# Fit the model\n",
    "x = df_test['visual_stimulus_ratio'].values\n",
    "y = df_test['left_choice'].values\n",
    "result = minimize(\n",
    "    lapse_logistic_independent,\n",
    "    initial_params,\n",
    "    args=(x, y),\n",
    "    bounds=[(0, 0.5), (0, 0.5), (None, None), (None, None)]\n",
    ")\n",
    "\n",
    "# Extract fitted parameters\n",
    "lapse_left, lapse_right, beta, x0 = result.x\n",
    "print(f\"Lapse Left: {lapse_left}, Lapse Right: {lapse_right}, Slope (Beta): {beta}, PSE (x0): {x0}\")\n",
    "\n",
    "# Generate predictions\n",
    "xs = np.linspace(X.min(), X.max(), 100).reshape(-1, 1)\n",
    "p_left = lapse_left + (1 - lapse_left - lapse_right) / (1 + np.exp(-beta * (xs - x0)))\n",
    "\n",
    "# Plot the fitted curve\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "sns.pointplot(\n",
    "    x='visual_stimulus_ratio',\n",
    "    y='left_choice',\n",
    "    data=df_test,\n",
    "    estimator=lambda x: np.mean(x),\n",
    "    color='blue',\n",
    "    markers='o',\n",
    "    errorbar=(\"ci\", 95),\n",
    "    ax=ax,\n",
    "    label='Observed Choices',\n",
    "    native_scale=True,\n",
    "    linestyles='',\n",
    ")\n",
    "ax.plot(xs, p_left, color='red', label='Lapse Logistic Fit (Independent)')\n",
    "ax.set_xlabel(\"Visual Stimulus ratio\")\n",
    "ax.set_ylabel(\"Probability of Left Choice\")\n",
    "ax.set_ylim(0, 1)\n",
    "plt.title(\"Psychometric Curve with Independent Lapses\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the following cell can be use to evaluate the model. It will be useful when comparing different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import log_loss\n",
    "from scipy.optimize import minimize\n",
    "import numpy as np\n",
    "\n",
    "# Define the lapse logistic function with independent lapses for left and right\n",
    "def lapse_logistic_independent(params, x, y):\n",
    "    lapse_left, lapse_right, beta, x0 = params\n",
    "    # Ensure lapse rates are within [0, 0.5]\n",
    "    lapse_left = np.clip(lapse_left, 0, 0.5)\n",
    "    lapse_right = np.clip(lapse_right, 0, 0.5)\n",
    "    # Predicted probabilities\n",
    "    p_left = lapse_left + (1 - lapse_left - lapse_right) / (1 + np.exp(-beta * (x - x0)))\n",
    "    # Negative log-likelihood\n",
    "    nll = -np.sum(y * np.log(p_left) + (1 - y) * np.log(1 - p_left))\n",
    "    return nll\n",
    "\n",
    "# Cross-validation setup\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)  # 5-fold cross-validation\n",
    "log_losses = []\n",
    "\n",
    "# Perform cross-validation\n",
    "for train_index, test_index in kf.split(df_test):\n",
    "    # Split the data\n",
    "    x_train, x_test = df_test['visual_stimulus_ratio'].values[train_index], df_test['visual_stimulus_ratio'].values[test_index]\n",
    "    y_train, y_test = df_test['left_choice'].values[train_index], df_test['left_choice'].values[test_index]\n",
    "    \n",
    "    # Initial parameter guesses: [lapse_left, lapse_right, beta, x0]\n",
    "    initial_params = [0.05, 0.05, 1, 0]\n",
    "    \n",
    "    # Fit the model on the training data\n",
    "    result = minimize(\n",
    "        lapse_logistic_independent,\n",
    "        initial_params,\n",
    "        args=(x_train, y_train),\n",
    "        bounds=[(0, 0.5), (0, 0.5), (None, None), (None, None)]\n",
    "    )\n",
    "    \n",
    "    # Extract fitted parameters\n",
    "    lapse_left, lapse_right, beta, x0 = result.x\n",
    "    \n",
    "    # Generate predictions on the test data\n",
    "    p_left_test = lapse_left + (1 - lapse_left - lapse_right) / (1 + np.exp(-beta * (x_test - x0)))\n",
    "    \n",
    "    # Calculate log loss for the test data\n",
    "    loss = log_loss(y_test, p_left_test)\n",
    "    log_losses.append(loss)\n",
    "\n",
    "# Print cross-validation results\n",
    "print(f\"Cross-Validation Log Losses: {log_losses}\")\n",
    "print(f\"Mean Log Loss: {np.mean(log_losses)}\")\n",
    "print(f\"Standard ratio of Log Loss: {np.std(log_losses)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# independent lapses model applied to the difference\n",
    "\n",
    "# Initial parameter guesses: [lapse_left, lapse_right, beta, x0]\n",
    "initial_params = [0.05, 0.05, 1, 0]\n",
    "\n",
    "# Fit the model\n",
    "x = df_test['visual_stimulus_diff'].values\n",
    "y = df_test['left_choice'].values\n",
    "result = minimize(\n",
    "    lapse_logistic_independent,\n",
    "    initial_params,\n",
    "    args=(x, y),\n",
    "    bounds=[(0, 0.5), (0, 0.5), (None, None), (None, None)]\n",
    ")\n",
    "\n",
    "# Extract fitted parameters\n",
    "lapse_left, lapse_right, beta, x0 = result.x\n",
    "print(f\"Lapse Left: {lapse_left}, Lapse Right: {lapse_right}, Slope (Beta): {beta}, PSE (x0): {x0}\")\n",
    "\n",
    "# Generate predictions\n",
    "xs = np.linspace(df_test['visual_stimulus_diff'].min(), df_test['visual_stimulus_diff'].max(), 100)\n",
    "p_left = lapse_left + (1 - lapse_left - lapse_right) / (1 + np.exp(-beta * (xs - x0)))\n",
    "\n",
    "# Plot the fitted curve\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "# bin the visual stimulus difference for better visualization\n",
    "df_test[\"visual_stimulus_diff_binned\"] = df_test['visual_stimulus_diff'] // 0.1 / 10\n",
    "sns.pointplot(\n",
    "    x='visual_stimulus_diff_binned',\n",
    "    y='left_choice',\n",
    "    data=df_test,\n",
    "    estimator=lambda x: np.mean(x),\n",
    "    color='blue',\n",
    "    markers='o',\n",
    "    errorbar=(\"ci\", 95),\n",
    "    ax=ax,\n",
    "    label='Observed Choices',\n",
    "    native_scale=True,\n",
    "    linestyles='',\n",
    ")\n",
    "ax.plot(xs, p_left, color='red', label='Lapse Logistic Fit')\n",
    "ax.set_xlabel(\"Visual Stimulus Difference\")\n",
    "ax.set_ylabel(\"Probability of Left Choice\")\n",
    "plt.title(\"Psychometric Curve with Independent Lapses\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "weight and stats for the different predictors:\n",
    "- visual stimulus ratio (you call it deviation)\n",
    "- visual stimulus diff. Nuo: change to \"total intensity on left port\"\n",
    "- port where the animal is coming from\n",
    "- interactions\n",
    "- Nuo: add another regressor: the previous correct choice\n",
    "\n",
    "We can play around with this things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get what the animal is doing, if it is alternating or repeating to the left or to the right\n",
    "df_test = dft.add_mouse_first_choice(df_test)\n",
    "df_test = dft.add_mouse_last_choice(df_test)\n",
    "df_test = dft.add_port_where_animal_comes_from(df_test)\n",
    "# turn the column \"previous_port_before_stimulus\" into a numeric value, where 0 is right and 1 is left\n",
    "df_test['previous_port_before_stimulus_numeric'] = df_test['previous_port_before_stimulus'].apply(\n",
    "    lambda x: 1 if x == 'left' else 0 if x == 'right' else np.nan\n",
    ")\n",
    "# turn the column \"roa_choice\" into a numeric value, where 0 is alternate and 1 is repeat\n",
    "df_test['roa_choice_numeric'] = df_test['roa_choice'].apply(\n",
    "    lambda x: 1 if x == 'repeat' else 0 if x == 'alternate' else np.nan\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add an interaction term between visual_stimulus_ratio and visual_stimulus_diff\n",
    "def interaction_calc(row):\n",
    "    is_left = 1 if row['correct_side'] == 'left' else -1\n",
    "    return row['visual_stimulus_ratio'] * row['visual_stimulus_diff'] * is_left\n",
    "\n",
    "df_test['interaction_term'] = df_test.apply(interaction_calc, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the intensity of left stimulus for each trial\n",
    "import ast\n",
    "df_test['left_ilumi'] = df_test.apply(\n",
    "    lambda row: ast.literal_eval(row['visual_stimulus'])[0] if row['correct_side'] == 'left' else ast.literal_eval(row['visual_stimulus'])[1],\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interaction_calc_brightness(row):\n",
    "    is_left = 1 if row['correct_side'] == 'left' else -1\n",
    "    return row['left_ilumi'] * row['visual_stimulus_ratio'] * is_left\n",
    "df_test['interaction_term_brightness'] = df_test.apply(interaction_calc_brightness, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the previous choice is left and correct as 1, or 0, remain NaN\n",
    "if \"last_choice\" not in df_test.columns:\n",
    "    df_test = dft.add_mouse_last_choice(df_test)\n",
    "df_test['previous_choice_left_correct'] = np.nan\n",
    "df_test['previous_choice_left_correct'] = df_test['previous_choice_left_correct'].astype(object)\n",
    "for mouse in df_test['subject'].unique():\n",
    "    for session in df_test[df_test.subject == mouse]['session'].unique():\n",
    "        df_mouse_session = df_test[np.logical_and(df_test['subject'] == mouse, df_test['session'] == session)]\n",
    "        df_mouse_session['last_choice_in_previous'] = df_mouse_session['last_choice'].shift(1, fill_value=np.nan)\n",
    "        df_mouse_session['correct_in_previous'] = df_mouse_session['correct'].shift(1, fill_value=np.nan)\n",
    "\n",
    "        series_to_append = np.where(\n",
    "            df_mouse_session['last_choice_in_previous'].isna() | df_mouse_session['correct_in_previous'].isna(),\n",
    "            None,\n",
    "            ((df_mouse_session['last_choice_in_previous'] == 'left') & (df_mouse_session['correct_in_previous'] == True)).astype(int)\n",
    "        )\n",
    "        df_test.loc[df_mouse_session.index, 'previous_choice_left_correct'] = series_to_append\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the previous choice is right and wrong as 1, or 0, remain NaN\n",
    "if \"last_choice\" not in df_test.columns:\n",
    "    df_test = dft.add_mouse_last_choice(df_test)\n",
    "df_test['previous_choice_right_wrong'] = np.nan\n",
    "df_test['previous_choice_right_wrong'] = df_test['previous_choice_right_wrong'].astype(object)\n",
    "for mouse in df_test['subject'].unique():\n",
    "    for session in df_test[df_test.subject == mouse]['session'].unique():\n",
    "        df_mouse_session = df_test[np.logical_and(df_test['subject'] == mouse, df_test['session'] == session)]\n",
    "        df_mouse_session['last_choice_in_previous'] = df_mouse_session['last_choice'].shift(1, fill_value=np.nan)\n",
    "        df_mouse_session['wrong_in_previous'] = df_mouse_session['correct'].shift(1, fill_value=np.nan)\n",
    "\n",
    "        series_to_append = np.where(\n",
    "            df_mouse_session['last_choice_in_previous'].isna() | df_mouse_session['wrong_in_previous'].isna(),\n",
    "            None,\n",
    "            ((df_mouse_session['last_choice_in_previous'] == 'right') & (df_mouse_session['wrong_in_previous'] == False)).astype(int)\n",
    "        )\n",
    "        df_test.loc[df_mouse_session.index, 'previous_choice_right_wrong'] = series_to_append\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mouse in df_test['subject'].unique():\n",
    "    for session in df_test[df_test.subject == mouse]['session'].unique():\n",
    "        df_mouse_session = df_test[np.logical_and(df_test['subject'] == mouse, df_test['session'] == session)]\n",
    "        df_mouse_session['last_choice_in_previous'] = df_mouse_session['last_choice'].shift(1, fill_value=np.nan)\n",
    "\n",
    "        series_to_append = np.where(\n",
    "            df_mouse_session['last_choice_in_previous'].isna(),\n",
    "            None,\n",
    "            (df_mouse_session['last_choice_in_previous'] == 'left').astype(int)\n",
    "        )\n",
    "        df_test.loc[df_mouse_session.index, 'previous_choice_left'] = series_to_append\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "parameters_for_fit = ['visual_stimulus_ratio',\n",
    "                      'previous_port_before_stimulus_numeric',\n",
    "                      'interaction_term',\n",
    "                      'previous_choice_left_correct',\n",
    "                      'previous_choice_right_wrong',\n",
    "                      'previous_choice_left', \n",
    "                      'interaction_term_brightness'\n",
    "                    ]\n",
    "variable_for_prediction = 'left_choice'\n",
    "\n",
    "# drop NaN values if any\n",
    "df_for_fit = df_test.dropna(subset=parameters_for_fit + [variable_for_prediction])\n",
    "df_for_fit = df_for_fit[parameters_for_fit].astype(int)\n",
    "\n",
    "# Prepare the independent variables\n",
    "X_multi = df_for_fit[parameters_for_fit].values\n",
    "X_multi_const = sm.add_constant(X_multi)\n",
    "y = df_for_fit[variable_for_prediction].values.astype(int)\n",
    "\n",
    "# Fit the logistic regression model with multiple regressors\n",
    "logit_model_multi = sm.Logit(y, X_multi_const).fit()\n",
    "\n",
    "# Display the summary, which includes p-values for all regressors\n",
    "print(logit_model_multi.summary(xname= [\"intercept\"] + parameters_for_fit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lecilab_behavior_analysis import plots\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "correct choice as output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"last_choice\" not in df_test.columns:\n",
    "    df_test = dft.add_mouse_last_choice(df_test)\n",
    "for mouse in df_test['subject'].unique():\n",
    "    for session in df_test[df_test.subject == mouse]['session'].unique():\n",
    "        df_mouse_session = df_test[np.logical_and(df_test['subject'] == mouse, df_test['session'] == session)]\n",
    "        df_mouse_session['last_choice_in_previous'] = df_mouse_session['last_choice'].shift(1, fill_value=np.nan)\n",
    "        df_mouse_session['correct_in_previous'] = df_mouse_session['correct'].shift(1, fill_value=np.nan)\n",
    "        \n",
    "        series_to_append = np.where(\n",
    "            df_mouse_session['last_choice_in_previous'].isna() | df_mouse_session['correct_in_previous'].isna(),\n",
    "            None,\n",
    "            (((df_mouse_session['last_choice_in_previous'] == 'left') & (df_mouse_session['left_choice'] == 1) & (df_mouse_session['correct_in_previous'] == True)) \n",
    "             | ((df_mouse_session['last_choice_in_previous'] == 'right') & (df_mouse_session['left_choice'] == 0) & (df_mouse_session['correct_in_previous'] == True))\n",
    "            ).astype(int)\n",
    "        )\n",
    "        df_test.loc[df_mouse_session.index, 'same_choice_correctPre'] = series_to_append\n",
    "\n",
    "        series_to_append = np.where(\n",
    "            df_mouse_session['last_choice_in_previous'].isna() | df_mouse_session['correct_in_previous'].isna(),\n",
    "            None,\n",
    "            (((df_mouse_session['last_choice_in_previous'] == 'left') & (df_mouse_session['left_choice'] == 0) & (df_mouse_session['correct_in_previous'] == False)) \n",
    "             | ((df_mouse_session['last_choice_in_previous'] == 'right') & (df_mouse_session['left_choice'] == 1) & (df_mouse_session['correct_in_previous'] == False))\n",
    "            ).astype(int)\n",
    "        )\n",
    "        df_test.loc[df_mouse_session.index, 'diff_choice_wrongPre'] = series_to_append"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['wrong_bright'] = df_test['visual_stimulus'].apply(lambda x: abs(eval(x)[1]))\n",
    "df_test['correct_bright'] = df_test['visual_stimulus'].apply(lambda x: abs(eval(x)[0]))\n",
    "df_test['bright_relative_correct_1'] = df_test['correct_bright'] / (df_test['wrong_bright'] + df_test['correct_bright'])\n",
    "df_test['bright_relative_correct_2'] = df_test['correct_bright'] / (df_test['wrong_bright'] - df_test['correct_bright'])\n",
    "\n",
    "df_test.dropna(subset=['same_choice_correctPre'], inplace=True)\n",
    "df_test['same_choice_correctPre'] = df_test['same_choice_correctPre'].astype(int)\n",
    "\n",
    "df_test.dropna(subset=['diff_choice_wrongPre'], inplace=True)\n",
    "df_test['diff_choice_wrongPre'] = df_test['diff_choice_wrongPre'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['correct_numeric'] = df_test['correct'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['abs_visual_stimulus_ratio'] = df_test['visual_stimulus_ratio'].abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"last_choice\" not in df_test.columns:\n",
    "    df_test = dft.add_mouse_last_choice(df_test)\n",
    "for mouse in df_test['subject'].unique():\n",
    "    for session in df_test[df_test.subject == mouse]['session'].unique():\n",
    "        df_mouse_session = df_test[np.logical_and(df_test['subject'] == mouse, df_test['session'] == session)]\n",
    "        df_mouse_session['last_choice_in_previous'] = df_mouse_session['last_choice'].shift(1, fill_value=np.nan)\n",
    "        df_mouse_session['correct_in_previous'] = df_mouse_session['correct'].shift(1, fill_value=np.nan)\n",
    "\n",
    "        df_test.loc[df_mouse_session.index, 'previous_choice'] = df_mouse_session['last_choice_in_previous']\n",
    "        df_test.loc[df_mouse_session.index, 'previous_correct'] = df_mouse_session['correct_in_previous']\n",
    "\n",
    "# Add the same choice as previous, where 1 is the same choice and 0 is a different choice\n",
    "        series_to_append = np.where(\n",
    "            df_mouse_session['last_choice_in_previous'].isna() | df_mouse_session['left_choice'].isna(),\n",
    "            None,\n",
    "            (((df_mouse_session['last_choice_in_previous'] == 'left') & (df_mouse_session['left_choice'] == 1)) \n",
    "             | ((df_mouse_session['last_choice_in_previous'] == 'right') & (df_mouse_session['left_choice'] == 0))\n",
    "            ).astype(int)\n",
    "        )\n",
    "        df_test.loc[df_mouse_session.index, 'same_choice_previous'] = series_to_append\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.dropna(subset=['same_choice_previous'], inplace=True)\n",
    "df_test['same_choice_previous'] = df_test['same_choice_previous'].astype(int)\n",
    "df_test.dropna(subset=['previous_correct'], inplace=True)\n",
    "df_test['previous_correct'] = df_test['previous_correct'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"last_choice\" not in df_test.columns:\n",
    "    df_test = dft.add_mouse_last_choice(df_test)\n",
    "for mouse in df_test['subject'].unique():\n",
    "    for session in df_test[df_test.subject == mouse]['session'].unique():\n",
    "        df_mouse_session = df_test[np.logical_and(df_test['subject'] == mouse, df_test['session'] == session)]\n",
    "        df_mouse_session['last_choice_in_previous'] = df_mouse_session['last_choice'].shift(1, fill_value=np.nan)\n",
    "        df_mouse_session['correct_in_previous'] = df_mouse_session['correct'].shift(1, fill_value=np.nan)\n",
    "        \n",
    "        # Define conditions for the 4 groups\n",
    "        conditions = [\n",
    "            ((df_mouse_session['last_choice_in_previous'] == 'left') & (df_mouse_session['left_choice'] == 1) & (df_mouse_session['correct_in_previous'] == True)) | ((df_mouse_session['last_choice_in_previous'] == 'right') & (df_mouse_session['left_choice'] == 0) & (df_mouse_session['correct_in_previous'] == True)),\n",
    "            ((df_mouse_session['last_choice_in_previous'] == 'left') & (df_mouse_session['left_choice'] == 1) & (df_mouse_session['correct_in_previous'] == False)) | ((df_mouse_session['last_choice_in_previous'] == 'right') & (df_mouse_session['left_choice'] == 0) & (df_mouse_session['correct_in_previous'] == False)),\n",
    "            ((df_mouse_session['last_choice_in_previous'] == 'left') & (df_mouse_session['left_choice'] == 0) & (df_mouse_session['correct_in_previous'] == True)) | ((df_mouse_session['last_choice_in_previous'] == 'right') & (df_mouse_session['left_choice'] == 1) & (df_mouse_session['correct_in_previous'] == True)),\n",
    "            ((df_mouse_session['last_choice_in_previous'] == 'left') & (df_mouse_session['left_choice'] == 0) & (df_mouse_session['correct_in_previous'] == False)) | ((df_mouse_session['last_choice_in_previous'] == 'right') & (df_mouse_session['left_choice'] == 1) & (df_mouse_session['correct_in_previous'] == False)),\n",
    "        ]\n",
    "\n",
    "        # Corresponding values\n",
    "        values = [2, -2, 1, -1] # same choice correct, same choice wrong, different choice correct, different choice wrong\n",
    "\n",
    "        # Assign group values, set to None if any isna\n",
    "        series_to_append = np.select(\n",
    "            condlist=conditions,\n",
    "            choicelist=values,\n",
    "            default=None\n",
    "        )\n",
    "        series_to_append = np.where(\n",
    "            df_mouse_session['last_choice_in_previous'].isna() | df_mouse_session['correct_in_previous'].isna() | df_mouse_session['left_choice'].isna(),\n",
    "            None,\n",
    "            series_to_append\n",
    "        )\n",
    "        df_test.loc[df_mouse_session.index, 'previous_choice_same_correct'] = series_to_append\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.dropna(subset=['previous_choice_same_correct'], inplace=True)\n",
    "df_test['previous_choice_same_correct'] = df_test['previous_choice_same_correct'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['wrong_bright_zscore'] = df_test.groupby('abs_visual_stimulus_ratio')['wrong_bright'].transform(lambda x: (x - x.mean()) / x.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_for_fit = ['abs_visual_stimulus_ratio',\n",
    "                      'wrong_bright', \n",
    "                      # 'wrong_bright_zscore',\n",
    "                      # 'bright_relative_correct_1',\n",
    "                      # 'bright_relative_correct_2',\n",
    "                      # 'same_choice_correctPre', \n",
    "                      # 'diff_choice_wrongPre', \n",
    "                      'same_choice_previous', \n",
    "                      'previous_correct', \n",
    "                      # 'previous_choice_same_correct',\n",
    "                    ]\n",
    "variable_for_prediction = 'correct_numeric'\n",
    "\n",
    "# drop NaN values if any\n",
    "df_for_fit = df_test.dropna(subset=parameters_for_fit + [variable_for_prediction])\n",
    "# Prepare the independent variables\n",
    "X_multi = df_for_fit[parameters_for_fit].values\n",
    "X_multi_const = sm.add_constant(X_multi)\n",
    "y = df_for_fit[variable_for_prediction].values.astype(int) \n",
    "# Fit the logistic regression model with multiple regressors\n",
    "logit_model_multi = sm.Logit(y, X_multi_const).fit()\n",
    "# Display the summary, which includes p-values for all regressors\n",
    "print(logit_model_multi.summary(xname= [\"intercept\"] + parameters_for_fit))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correct wrong psychometric curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "for i, linecolor in zip(df_test[df_test['previous_choice'] == 'left'].groupby('previous_correct'), ['red', 'green']):\n",
    "    plots.psychometric_plot_by_discreVal(df = i[1], \n",
    "                                         x = 'visual_stimulus_ratio', \n",
    "                                         y = 'left_choice', \n",
    "                                         ax=ax[0],\n",
    "                                         markercolor='k',\n",
    "                                         markers='o',\n",
    "                                         errorbar=(\"ci\", 95),\n",
    "                                         markerlabel=None,\n",
    "                                         markersize=5, \n",
    "                                         linecolor=linecolor, \n",
    "                                         linelabel='previous ' + str(i[0])\n",
    "                                        )\n",
    "\n",
    "for i, linecolor in zip(df_test[df_test['previous_choice'] == 'right'].groupby('previous_correct'), ['red', 'green']):\n",
    "    plots.psychometric_plot_by_discreVal(df = i[1], \n",
    "                                         x = 'visual_stimulus_ratio', \n",
    "                                         y = 'left_choice', \n",
    "                                         ax=ax[1],\n",
    "                                         markercolor='k',\n",
    "                                         markers='o',\n",
    "                                         errorbar=(\"ci\", 95),\n",
    "                                         markerlabel=None,\n",
    "                                         markersize=5, \n",
    "                                         linecolor=linecolor, \n",
    "                                         linelabel='previous ' + str(i[0])\n",
    "                                        )\n",
    "ax[0].legend()\n",
    "ax[0].set_title(\"Left Choice Previous\")\n",
    "ax[1].legend()\n",
    "ax[1].set_title(\"Right Choice Previous\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "for i, linecolor in zip(df_test[df_test['previous_correct'] == True].groupby('previous_choice'), ['gold', 'lightskyblue']):\n",
    "    plots.psychometric_plot_by_discreVal(df = i[1], \n",
    "                                         x = 'visual_stimulus_ratio', \n",
    "                                         y = 'left_choice', \n",
    "                                         ax=ax[0],\n",
    "                                         markercolor='k',\n",
    "                                         markers='o',\n",
    "                                         errorbar=(\"ci\", 95),\n",
    "                                         markerlabel=None,\n",
    "                                         markersize=5, \n",
    "                                         linecolor=linecolor, \n",
    "                                         linelabel='previous ' + str(i[0])\n",
    "                                        )\n",
    "\n",
    "for i, linecolor in zip(df_test[df_test['previous_correct'] == False].groupby('previous_choice'), ['gold', 'lightskyblue']):\n",
    "    plots.psychometric_plot_by_discreVal(df = i[1], \n",
    "                                         x = 'visual_stimulus_ratio', \n",
    "                                         y = 'left_choice', \n",
    "                                         ax=ax[1],\n",
    "                                         markercolor='k',\n",
    "                                         markers='o',\n",
    "                                         errorbar=(\"ci\", 95),\n",
    "                                         markerlabel=None,\n",
    "                                         markersize=5, \n",
    "                                         linecolor=linecolor, \n",
    "                                         linelabel='previous ' + str(i[0])\n",
    "                                        )\n",
    "ax[0].legend()\n",
    "ax[0].set_title(\"Correct Choice Previous\")\n",
    "ax[1].legend()\n",
    "ax[1].set_title(\"Incorrect Choice Previous\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's use the absolute value of the lowest visual stimulus as a proxy for the brightness of the visual stimulus\n",
    "df_test['visual_stimulus_lowest'] = df_test['visual_stimulus'].apply(lambda x: abs(eval(x)[0]) if eval(x)[0] < eval(x)[1] else abs(eval(x)[1]))\n",
    "# create 10 bins for the absolute value of the lowest visual stimulus\n",
    "min_value = df_test['visual_stimulus_lowest'].min()\n",
    "max_value = df_test['visual_stimulus_lowest'].max()\n",
    "bins = np.linspace(min_value, max_value, 11)\n",
    "df_test['visual_stimulus_lowest_binned'] = pd.cut(df_test['visual_stimulus_lowest'], bins=bins, labels=[f\"{b:.2f}\" for b in bins[:-1]])\n",
    "# create a pivot table with the visual stimulus ratio and absolute value of the lowest visual stimulus\n",
    "pivot_table_abs = df_test.pivot_table(\n",
    "    index='visual_stimulus_lowest_binned',\n",
    "    columns='visual_stimulus_ratio',\n",
    "    values='left_choice',\n",
    "    aggfunc='mean',\n",
    "    observed=True\n",
    ")\n",
    "# plot the heatmap\n",
    "plt.figure(figsize=(5, 5))\n",
    "sns.heatmap(pivot_table_abs, cmap='coolwarm', annot=True, fmt=\".2f\", cbar_kws={'label': 'Probability of Left Choice'})\n",
    "plt.xlabel(\"Visual Stimulus ratio\")\n",
    "plt.ylabel(\"Absolute Value of Lowest Visual Stimulus\")\n",
    "plt.title(\"Heatmap of Probability of Left Choice\")\n",
    "# rotate the y-axis labels\n",
    "plt.yticks(rotation=0)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform visual_stimulus_lowest_binned to a numeric value for plotting\n",
    "df_test['visual_stimulus_lowest_binned_num'] = pd.to_numeric(df_test['visual_stimulus_lowest_binned'], errors='coerce')\n",
    "\n",
    "# make two plots, one for when the animals comes from the left and one for when it comes from the right\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 5), sharey=True)\n",
    "# Plot for when the animal comes from the left\n",
    "for ax, side in zip(axs.ravel(), ['left', 'right']):\n",
    "    df_side = df_test[df_test['previous_port_before_stimulus'] == side]\n",
    "    for i in df_side.groupby('visual_stimulus_ratio'):\n",
    "        df_i = i[1].sort_values(by='visual_stimulus_lowest_binned_num')\n",
    "        # drop nan\n",
    "        df_i = df_i.dropna(subset=['visual_stimulus_lowest_binned_num'])\n",
    "        X = df_i['visual_stimulus_lowest_binned_num'].values.reshape(-1, 1)\n",
    "        y = df_i['left_choice'].values.astype(int)\n",
    "        model = LogisticRegression()\n",
    "        model.fit(X, y)\n",
    "        y_pred = model.predict(X)\n",
    "        y_prob = model.predict_proba(X)[:, 1]\n",
    "        ax.plot(X, y_prob, label=f\"Visual Stimulus ratio: {i[0]}\")\n",
    "    ax.set_xlabel(\"Absolute Value of Lowest Visual Stimulus\")\n",
    "    ax.set_ylabel(\"Probability of Left Choice\")\n",
    "    ax.legend()\n",
    "    ax.set_title(f\"Last Choice Before Stimulus: {side.capitalize()}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the lapse model independently considering previous choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "\n",
    "colors = [\"blue\", \"orange\"]\n",
    "\n",
    "for color, side in zip(colors, ['left', 'right']):\n",
    "    df_side = df_test[df_test['previous_port_before_stimulus'] == side]\n",
    "    # Fit the model\n",
    "    x = df_side['visual_stimulus_ratio'].values\n",
    "    y = df_side['left_choice'].values\n",
    "    result = minimize(\n",
    "        lapse_logistic_independent,\n",
    "        initial_params,\n",
    "        args=(x, y),\n",
    "        bounds=[(0, 0.5), (0, 0.5), (None, None), (None, None)]\n",
    "    )\n",
    "\n",
    "    # Extract fitted parameters\n",
    "    lapse_left, lapse_right, beta, x0 = result.x\n",
    "    print(f\"Side: {side}, Lapse Left: {lapse_left}, Lapse Right: {lapse_right}, Slope (Beta): {beta}, PSE (x0): {x0}\")\n",
    "\n",
    "    # Generate predictions\n",
    "    xs = np.linspace(df_side['visual_stimulus_ratio'].min(), df_side['visual_stimulus_ratio'].max(), 100)\n",
    "    p_left = lapse_left + (1 - lapse_left - lapse_right) / (1 + np.exp(-beta * (xs - x0)))\n",
    "\n",
    "    # Plot the fitted curve\n",
    "\n",
    "    sns.pointplot(\n",
    "        x='visual_stimulus_ratio',\n",
    "        y='left_choice',\n",
    "        data=df_side,\n",
    "        estimator=lambda x: np.mean(x),\n",
    "        color=color,\n",
    "        markers='o',\n",
    "        errorbar=(\"ci\", 95),\n",
    "        ax=ax,\n",
    "        label=f'Choices when coming from {side}',\n",
    "        native_scale=True,\n",
    "        linestyles='',\n",
    "    )\n",
    "    ax.plot(xs, p_left, color=color, label='Lapse Logistic Fit')\n",
    "    ax.set_xlabel(\"Visual Stimulus ratio\")\n",
    "    ax.set_ylabel(\"Probability of Left Choice\")\n",
    "    plt.title(f\"Psychometric Curves\")\n",
    "    ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I kept what you did for comparison here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is interesting to compare the effects of the relative difference between the two visual stimuli,\n",
    "# and the absolute difference between them.\n",
    "\n",
    "# Maybe what we can do is to train another logistic regression model, adding as well the absolute difference\n",
    "# between the two visual stimuli, and see how it affects the probability of a left choice.\n",
    "# Do you know what I mean?\n",
    "\n",
    "for i in df_test.groupby('visual_stimulus_ratio'):\n",
    "    df_i = i[1].sort_values(by='visual_stimulus_diff')\n",
    "    X = df_i['visual_stimulus_diff'].values.reshape(-1, 1)\n",
    "    y = df_i['left_choice'].values.astype(int)\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X, y)\n",
    "    y_pred = model.predict(X)\n",
    "    y_prob = model.predict_proba(X)[:, 1]\n",
    "    plt.plot(X, y_prob, label=f\"Visual Stimulus ratio: {i[0]}\")\n",
    "    plt.legend()\n",
    "plt.xlabel(\"Visual Stimulus Difference\")\n",
    "plt.ylabel(\"Probability of Left Choice\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple animals analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dic = {}\n",
    "for mouse in animals:\n",
    "    local_path = Path(utils.get_outpath()) / Path(tv_projects[1]) / Path(\"sessions\") / Path(mouse)\n",
    "    # create the directory if it doesn't exist\n",
    "    local_path.mkdir(parents=True, exist_ok=True)\n",
    "    # download the session data\n",
    "    utils.rsync_session_data(\n",
    "        project_name=tv_projects[1],\n",
    "        animal=mouse,\n",
    "        local_path=str(local_path),\n",
    "        credentials=utils.get_idibaps_cluster_credentials(),\n",
    "    )\n",
    "    # load the data\n",
    "    df_dic[mouse] = pd.read_csv(local_path / Path(f'{mouse}.csv'), sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dic_hard = {}\n",
    "for df_name, df in zip(df_dic.keys(), df_dic.values()):\n",
    "    if 'TwoAFC_visual_hard' in df[\"current_training_stage\"].unique():\n",
    "        df = df.dropna(subset = ['visual_stimulus'])\n",
    "        df = df[df[\"current_training_stage\"] == \"TwoAFC_visual_hard\"]\n",
    "\n",
    "        df['visual_stimulus_ratio'] = df['visual_stimulus'].apply(lambda x: abs(round(eval(x)[0] / eval(x)[1], 4)))\n",
    "        df['visual_stimulus_ratio'] = df.apply(\n",
    "            lambda row: row['visual_stimulus_ratio'] if row['correct_side'] == 'left' else -row['visual_stimulus_ratio'],\n",
    "            axis=1\n",
    "        )\n",
    "        df['visual_stimulus_diff'] = df['visual_stimulus'].apply(lambda x: abs(eval(x)[0] - eval(x)[1]))\n",
    "        df['visual_stimulus_diff'] = df.apply(\n",
    "            lambda row: row['visual_stimulus_diff'] if row['correct_side'] == 'left' else -row['visual_stimulus_diff'],\n",
    "            axis=1\n",
    "        )\n",
    "        df[\"visual_stimulus_diff_binned\"] = df['visual_stimulus_diff'] // 0.1\n",
    "        df = dft.add_mouse_first_choice(df)\n",
    "        df['left_choice'] = df['first_choice'].apply(lambda x: 1 if x == 'left' else 0)\n",
    "        \n",
    "        df_dic_hard[df_name] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratio_diffBin_inter_p = pd.DataFrame()\n",
    "df_ratio_diffBin_inter_coef = pd.DataFrame()\n",
    "for df_name, df in zip(df_dic_hard.keys(), df_dic_hard.values()):\n",
    "    df['interaction_term'] = df.apply(interaction_calc, axis=1)\n",
    "    # Prepare the independent variables\n",
    "    X_multi = df[['visual_stimulus_ratio', 'visual_stimulus_diff_binned', 'interaction_term']]\n",
    "    X_multi_const = sm.add_constant(X_multi)\n",
    "    y = df['left_choice'].values.astype(int)\n",
    "\n",
    "    # Fit the logistic regression model with multiple regressors\n",
    "    logit_model_multi = sm.Logit(y, X_multi_const).fit()\n",
    "\n",
    "    df_ratio_diffBin_inter_p[df_name] = logit_model_multi.pvalues\n",
    "    df_ratio_diffBin_inter_coef[df_name] = logit_model_multi.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratio_diff_inter_p = pd.DataFrame()\n",
    "df_ratio_diff_inter_coef = pd.DataFrame()\n",
    "for df_name, df in zip(df_dic_hard.keys(), df_dic_hard.values()):\n",
    "    df['interaction_term'] = df.apply(interaction_calc, axis=1)\n",
    "    # Prepare the independent variables\n",
    "    X_multi = df[['visual_stimulus_ratio', 'visual_stimulus_diff', 'interaction_term']]\n",
    "    X_multi_const = sm.add_constant(X_multi)\n",
    "    y = df['left_choice'].values.astype(int)\n",
    "\n",
    "    # Fit the logistic regression model with multiple regressors\n",
    "    logit_model_multi = sm.Logit(y, X_multi_const).fit()\n",
    "\n",
    "    df_ratio_diff_inter_p[df_name] = logit_model_multi.pvalues\n",
    "    df_ratio_diff_inter_coef[df_name] = logit_model_multi.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratio_diffBin_inter_p.rename(index={'visual_stimulus_ratio': 'ratio', 'visual_stimulus_diff_binned': 'diff', 'interaction_term': 'inter'}, inplace=True)\n",
    "df_ratio_diff_inter_p.rename(index={'visual_stimulus_ratio': 'ratio', 'visual_stimulus_diff': 'diff', 'interaction_term': 'inter'}, inplace=True)\n",
    "for df_name, color in zip(df_dic_hard.keys(), sns.color_palette(\"colorblind\", len(df_dic_hard))):\n",
    "    plt.plot (df_ratio_diff_inter_p[df_name], label=df_name+ 'ratio_diff_inter', color=color)\n",
    "    plt.plot (df_ratio_diffBin_inter_p[df_name], label=df_name+ 'ratio_diffBin_inter', color=color, linestyle='--')\n",
    "plt.axhline(y=0.05, color='k', linestyle='--', label='p-value threshold')\n",
    "plt.xlabel(\"Regressors\")\n",
    "plt.ylabel(\"p-value\")\n",
    "plt.legend(loc = (1 , 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratio_diffBin_inter_coef.rename(index={'visual_stimulus_ratio': 'ratio', 'visual_stimulus_diff_binned': 'diff', 'interaction_term': 'inter'}, inplace=True)\n",
    "df_ratio_diff_inter_coef.rename(index={'visual_stimulus_ratio': 'ratio', 'visual_stimulus_diff': 'diff', 'interaction_term': 'inter'}, inplace=True)\n",
    "for df_name, color in zip(df_dic_hard.keys(), sns.color_palette(\"colorblind\", len(df_dic_hard))):\n",
    "    plt.plot (df_ratio_diff_inter_coef[df_name], label=df_name+ 'ratio_diff_inter', color=color)\n",
    "    plt.plot (df_ratio_diffBin_inter_coef[df_name], label=df_name+ 'ratio_diffBin_inter', color=color, linestyle='--')\n",
    "plt.xlabel(\"Regressors\")\n",
    "plt.ylabel(\"Coefficient\")\n",
    "plt.legend(loc = (1 , 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
