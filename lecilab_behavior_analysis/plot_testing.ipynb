{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import lecilab_behavior_analysis.utils as utils\n",
    "from pathlib import Path\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mouse = \"mouse2\"\n",
    "# df = utils.load_example_data(mouse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "socket.gethostname()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from cluster\n",
    "tv_projects = utils.get_server_projects()\n",
    "print(tv_projects)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# see the available animals\n",
    "animals = utils.get_animals_in_project(tv_projects[1])\n",
    "print(animals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the data for a specific animal\n",
    "mouse = \"ACV007\"\n",
    "local_path = Path(utils.get_outpath()) / Path(tv_projects[1]) / Path(\"sessions\") / Path(mouse)\n",
    "# create the directory if it doesn't exist\n",
    "local_path.mkdir(parents=True, exist_ok=True)\n",
    "# download the session data\n",
    "utils.rsync_session_data(\n",
    "    project_name=tv_projects[1],\n",
    "    animal=mouse,\n",
    "    local_path=str(local_path),\n",
    "    credentials=utils.get_idibaps_cluster_credentials(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "df = pd.read_csv(local_path / Path(f'{mouse}.csv'), sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lecilab_behavior_analysis.plots as plots\n",
    "import lecilab_behavior_analysis.df_transforms as dft\n",
    "df = dft.fill_missing_data(df)\n",
    "\n",
    "# add a column with the date for the day\n",
    "df = dft.add_day_column_to_df(df)\n",
    "\n",
    "# create a figure with 1 axis for the calendar plot\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax_cal = plt.subplots(figsize=(10, 5), dpi=300)\n",
    "# generate the calendar plot\n",
    "dates_df = dft.get_dates_df(df)\n",
    "cal_image = plots.rasterize_plot(plots.training_calendar_plot(dates_df), dpi=300)\n",
    "# paste the calendar plot filling the entire axis\n",
    "ax_cal.imshow(cal_image)\n",
    "ax_cal.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lecilab_behavior_analysis.figure_maker import subject_progress_figure\n",
    "fig = subject_progress_figure(df, perf_window=100, summary_matrix_plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lecilab_behavior_analysis.figure_maker import session_summary_figure\n",
    "from lecilab_behavior_analysis.df_transforms import add_trial_of_day_column_to_df, add_day_column_to_df\n",
    "# select the session you want to plot\n",
    "date = \"2025-05-06\"\n",
    "df = add_day_column_to_df(df)\n",
    "df = add_trial_of_day_column_to_df(df)\n",
    "sdf = df[df[\"year_month_day\"] == date]\n",
    "fig = session_summary_figure(sdf, mouse, perf_window=15, width=10, height=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from scipy.optimize import curve_fit\n",
    "import df_transforms as dft\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df.dropna(subset = ['visual_stimulus'])\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "for i, ax in zip(df_test.groupby('current_training_stage').groups.keys(), [ax1, ax2]):\n",
    "    df_test_sub = df_test[df_test[\"current_training_stage\"] == i]\n",
    "    df_test_sub['visual_stimulus_devi'] = df_test_sub['visual_stimulus'].apply(lambda x: abs(round(eval(x)[0] / eval(x)[1], 4)))\n",
    "    # This was good in order to make the fit work for both left and right choices!\n",
    "    df_test_sub['visual_stimulus_devi'] = df_test_sub.apply(\n",
    "        lambda row: row['visual_stimulus_devi'] if row['correct_side'] == 'left' else -row['visual_stimulus_devi'],\n",
    "        axis=1\n",
    "    )\n",
    "    df_test_sub = dft.add_mouse_first_choice(df_test_sub)\n",
    "    df_test_sub['left_choice_new'] = df_test_sub['first_choice'].apply(lambda x: 1 if x == 'left' else 0)\n",
    "    \n",
    "    # Now we can fit the data and visualize the results\n",
    "    X = df_test_sub['visual_stimulus_devi'].values.reshape(-1, 1)\n",
    "    y = df_test_sub['left_choice_new'].values.astype(int)\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X, y)\n",
    "\n",
    "    # Now we have a model that predicts the probability of a left choice based on ANY visual stimulus deviation (xs).\n",
    "    # For plotting, we can generate a range of values for the visual stimulus deviation\n",
    "    import numpy as np\n",
    "    xs = np.linspace(df_test_sub['visual_stimulus_devi'].min(), df_test_sub['visual_stimulus_devi'].max(), 100).reshape(-1, 1)\n",
    "    y_prob = model.predict_proba(xs)[:, 1]\n",
    "\n",
    "    # Plot the actual choices of the mouse\n",
    "\n",
    "    sns.pointplot(\n",
    "        x='visual_stimulus_devi',\n",
    "        y='left_choice_new',\n",
    "        data=df_test_sub,\n",
    "        estimator=lambda x: np.mean(x),\n",
    "        color='blue',\n",
    "        markers='o',\n",
    "        errorbar=(\"ci\", 95),\n",
    "        ax=ax,\n",
    "        label='Observed Choices',\n",
    "        native_scale= True,\n",
    "        linestyles='',\n",
    "    )\n",
    "\n",
    "    # overlay the fitted logistic regression curve\n",
    "    ax.plot(xs, y_prob, color='red', label='Logistic Regression Fit')\n",
    "    ax.set_xlabel(\"Visual Stimulus Deviation\")\n",
    "    ax.set_ylabel(\"Probability of Left Choice\")\n",
    "    plt.title(\"Psychometric Curve\")\n",
    "    plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df.dropna(subset = ['visual_stimulus'])\n",
    "df_test['visual_stimulus_devi'] = df_test['visual_stimulus'].apply(lambda x: abs(round(eval(x)[0] / eval(x)[1], 4)))\n",
    "# This was good in order to make the fit work for both left and right choices!\n",
    "df_test['visual_stimulus_devi'] = df_test.apply(\n",
    "    lambda row: row['visual_stimulus_devi'] if row['correct_side'] == 'left' else -row['visual_stimulus_devi'],\n",
    "    axis=1\n",
    ")\n",
    "df_test = dft.add_mouse_first_choice(df_test)\n",
    "df_test['left_choice_new'] = df_test['first_choice'].apply(lambda x: 1 if x == 'left' else 0)\n",
    "\n",
    "# By the way I am naming columns weirdly, just so you can play around with the different solutions and see how they work.\n",
    "# Once we have what we need, we should clean up the code and use more meaningful names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_sorted = df_test.sort_values(by='visual_stimulus_diff')\n",
    "X = df_test_sorted['visual_stimulus_diff'].values.reshape(-1, 1)\n",
    "y = df_test_sorted['left_choice'].values.astype(int)\n",
    "model = LogisticRegression()\n",
    "model.fit(X, y)\n",
    "y_pred = model.predict(X)\n",
    "y_prob = model.predict_proba(X)[:, 1]\n",
    "plt.plot(X, y_prob)\n",
    "\n",
    "plt.xlabel(\"Visual Stimulus Difference\")\n",
    "plt.ylabel(\"Probability of Left Choice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test[df_test[\"current_training_stage\"] == \"TwoAFC_visual_hard\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can fit the data and visualize the results\n",
    "X = df_test['visual_stimulus_devi'].values.reshape(-1, 1)\n",
    "y = df_test['left_choice_new'].values.astype(int)\n",
    "model = LogisticRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Now we have a model that predicts the probability of a left choice based on ANY visual stimulus deviation (xs).\n",
    "# For plotting, we can generate a range of values for the visual stimulus deviation\n",
    "import numpy as np\n",
    "xs = np.linspace(df_test['visual_stimulus_devi'].min(), df_test['visual_stimulus_devi'].max(), 100).reshape(-1, 1)\n",
    "y_prob = model.predict_proba(xs)[:, 1]\n",
    "\n",
    "# Plot the actual choices of the mouse\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "sns.pointplot(\n",
    "    x='visual_stimulus_devi',\n",
    "    y='left_choice_new',\n",
    "    data=df_test,\n",
    "    estimator=lambda x: np.mean(x),\n",
    "    color='blue',\n",
    "    markers='o',\n",
    "    errorbar=(\"ci\", 95),\n",
    "    ax=ax,\n",
    "    label='Observed Choices',\n",
    "    native_scale= True,\n",
    "    linestyles='',\n",
    ")\n",
    "\n",
    "# overlay the fitted logistic regression curve\n",
    "ax.plot(xs, y_prob, color='red', label='Logistic Regression Fit')\n",
    "ax.set_xlabel(\"Visual Stimulus Deviation\")\n",
    "ax.set_ylabel(\"Probability of Left Choice\")\n",
    "plt.title(\"Psychometric Curve\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['visual_stimulus_diff'] = df_test['visual_stimulus'].apply(lambda x: abs(eval(x)[0] - eval(x)[1]))\n",
    "df_test['visual_stimulus_diff'] = df_test.apply(\n",
    "    lambda row: row['visual_stimulus_diff'] if row['correct_side'] == 'left' else -row['visual_stimulus_diff'],\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['left_choice_new'] = df_test['first_choice'].apply(lambda x: 1 if x == 'left' else 0)\n",
    "\n",
    "# Now we can fit the data and visualize the results\n",
    "X = df_test.sort_values(by='visual_stimulus_diff')['visual_stimulus_diff'].values.reshape(-1, 1)\n",
    "y = df_test.sort_values(by='visual_stimulus_diff')['left_choice_new'].values.astype(int)\n",
    "model = LogisticRegression()\n",
    "model.fit(X, y)\n",
    "y_prob = model.predict_proba(X)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Generate a grid of values for visualization\n",
    "devi_range = np.linspace(df_test['visual_stimulus_devi'].min(), df_test['visual_stimulus_devi'].max(), 50)\n",
    "diff_range = np.linspace(df_test['visual_stimulus_diff'].min(), df_test['visual_stimulus_diff'].max(), 50)\n",
    "devi_grid, diff_grid = np.meshgrid(devi_range, diff_range)\n",
    "interaction_grid = devi_grid * diff_grid\n",
    "\n",
    "# Flatten the grid for prediction\n",
    "grid_data = np.column_stack((devi_grid.ravel(), diff_grid.ravel(), interaction_grid.ravel()))\n",
    "grid_data_const = sm.add_constant(grid_data)\n",
    "\n",
    "# Predict probabilities using the model\n",
    "probabilities = logit_model_multi.predict(grid_data_const).reshape(devi_grid.shape)\n",
    "\n",
    "# Plot the 3D surface\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "surf = ax.plot_surface(devi_grid, diff_grid, probabilities, cmap='viridis', alpha=0.8)\n",
    "ax.set_xlabel('Visual Stimulus Deviation')\n",
    "ax.set_ylabel('Visual Stimulus Difference')\n",
    "ax.set_zlabel('Probability of Left Choice')\n",
    "plt.title('Influence of Regressors on Probability of Left Choice')\n",
    "fig.colorbar(surf, shrink=0.5, aspect=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is interesting to compare the effects of the relative difference between the two visual stimuli,\n",
    "# and the absolute difference between them.\n",
    "\n",
    "# Maybe what we can do is to train another logistic regression model, adding as well the absolute difference\n",
    "# between the two visual stimuli, and see how it affects the probability of a left choice.\n",
    "# Do you know what I mean?\n",
    "\n",
    "for i in df_test.groupby('visual_stimulus_devi'):\n",
    "    df_i = i[1].sort_values(by='visual_stimulus_diff')\n",
    "    X = df_i['visual_stimulus_diff'].values.reshape(-1, 1)\n",
    "    y = df_i['left_choice'].values.astype(int)\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X, y)\n",
    "    y_pred = model.predict(X)\n",
    "    y_prob = model.predict_proba(X)[:, 1]\n",
    "    plt.plot(X, y_prob, label=f\"Visual Stimulus Deviation: {i[0]}\")\n",
    "    plt.legend()\n",
    "plt.xlabel(\"Visual Stimulus Difference\")\n",
    "plt.ylabel(\"Probability of Left Choice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's plot it as matrix, with the values being the probability of a left choice.\n",
    "# in the x axis we will have the visual stimulus deviation,\n",
    "# and in the y axis we will have the visual stimulus difference.\n",
    "import seaborn as sns\n",
    "# create a pivot table with the visual stimulus deviation and difference\n",
    "pivot_table = df_test.pivot_table(\n",
    "    index='visual_stimulus_diff_binned',\n",
    "    columns='visual_stimulus_devi',\n",
    "    values='left_choice_new',\n",
    "    aggfunc='mean'\n",
    ")\n",
    "# plot the heatmap\n",
    "plt.figure(figsize=(5, 5))\n",
    "sns.heatmap(pivot_table, cmap='coolwarm', annot=True, fmt=\".2f\", cbar_kws={'label': 'Probability of Left Choice'})\n",
    "plt.xlabel(\"Visual Stimulus Deviation\")\n",
    "plt.ylabel(\"Visual Stimulus Difference\")\n",
    "plt.title(\"Heatmap of Probability of Left Choice\")\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Add an interaction term between visual_stimulus_devi and visual_stimulus_diff\n",
    "def interaction_calc(row):\n",
    "    is_left = 1 if row['correct_side'] == 'left' else -1\n",
    "    return row['visual_stimulus_devi'] * row['visual_stimulus_diff_binned'] * is_left\n",
    "df_test['interaction_term'] = df_test.apply(interaction_calc, axis=1)\n",
    "\n",
    "\n",
    "# Prepare the independent variables\n",
    "X_multi = df_test[['visual_stimulus_devi', 'visual_stimulus_diff_binned', 'interaction_term']]\n",
    "X_multi_const = sm.add_constant(X_multi)\n",
    "y = df_test['left_choice_new'].values.astype(int)\n",
    "\n",
    "# Fit the logistic regression model with multiple regressors\n",
    "logit_model_multi = sm.Logit(y, X_multi_const).fit()\n",
    "\n",
    "# Display the summary, which includes p-values for all regressors\n",
    "print(logit_model_multi.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Generate a grid of values for visualization\n",
    "devi_range = np.linspace(df_test['visual_stimulus_devi'].min(), df_test['visual_stimulus_devi'].max(), 50)\n",
    "diff_range = np.linspace(df_test['visual_stimulus_diff'].min(), df_test['visual_stimulus_diff'].max(), 50)\n",
    "devi_grid, diff_grid = np.meshgrid(devi_range, diff_range)\n",
    "interaction_grid = devi_grid * diff_grid\n",
    "\n",
    "# Flatten the grid for prediction\n",
    "grid_data = np.column_stack((devi_grid.ravel(), diff_grid.ravel(), interaction_grid.ravel()))\n",
    "grid_data_const = sm.add_constant(grid_data)\n",
    "\n",
    "# Predict probabilities using the model\n",
    "probabilities = logit_model_multi.predict(grid_data_const).reshape(devi_grid.shape)\n",
    "\n",
    "# Plot the 3D surface\n",
    "fig = plt.figure(figsize=(10, 7))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "surf = ax.plot_surface(devi_grid, diff_grid, probabilities, cmap='viridis', alpha=0.8)\n",
    "ax.set_xlabel('Visual Stimulus Deviation')\n",
    "ax.set_ylabel('Visual Stimulus Difference')\n",
    "ax.set_zlabel('Probability of Left Choice')\n",
    "plt.title('Influence of Regressors on Probability of Left Choice')\n",
    "fig.colorbar(surf, shrink=0.5, aspect=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, instead of the difference, let's use the absolute value of the lowest visual stimulus\n",
    "# This is the absolute value of the lowest visual stimulus\n",
    "df_test['visual_stimulus_lowest'] = df_test['visual_stimulus'].apply(lambda x: abs(eval(x)[0]) if eval(x)[0] < eval(x)[1] else abs(eval(x)[1]))\n",
    "# create 10 bins for the absolute value of the lowest visual stimulus\n",
    "min_value = df_test['visual_stimulus_lowest'].min()\n",
    "max_value = df_test['visual_stimulus_lowest'].max()\n",
    "bins = np.linspace(min_value, max_value, 11)\n",
    "df_test['visual_stimulus_lowest_binned'] = pd.cut(df_test['visual_stimulus_lowest'], bins=bins, labels=[f\"{b:.2f}\" for b in bins[:-1]])\n",
    "# create a pivot table with the visual stimulus deviation and absolute value of the lowest visual stimulus\n",
    "pivot_table_abs = df_test.pivot_table(\n",
    "    index='visual_stimulus_lowest_binned',\n",
    "    columns='visual_stimulus_devi',\n",
    "    values='left_choice_new',\n",
    "    aggfunc='mean',\n",
    "    observed=True\n",
    ")\n",
    "# plot the heatmap\n",
    "plt.figure(figsize=(5, 5))\n",
    "sns.heatmap(pivot_table_abs, cmap='coolwarm', annot=True, fmt=\".2f\", cbar_kws={'label': 'Probability of Left Choice'})\n",
    "plt.xlabel(\"Visual Stimulus Deviation\")\n",
    "plt.ylabel(\"Absolute Value of Lowest Visual Stimulus\")\n",
    "plt.title(\"Heatmap of Probability of Left Choice\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pointplot(\n",
    "    x='visual_stimulus_diff_binned',\n",
    "    y='left_choice_new',\n",
    "    data=df_test,\n",
    "    estimator=lambda x: np.mean(x),\n",
    "    color='blue',\n",
    "    markers='o',\n",
    "    errorbar=(\"ci\", 95),\n",
    "    native_scale=True,\n",
    "    linestyles='',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's plot it as matrix, with the values being the probability of a left choice.\n",
    "# in the x axis we will have the visual stimulus deviation,\n",
    "# and in the y axis we will have the visual stimulus difference.\n",
    "import seaborn as sns\n",
    "# create a pivot table with the visual stimulus deviation and difference\n",
    "pivot_table = df_test.pivot_table(\n",
    "    index='visual_stimulus_diff_binned',\n",
    "    columns='visual_stimulus_devi',\n",
    "    values='left_choice_new',\n",
    "    aggfunc='mean'\n",
    ")\n",
    "# plot the heatmap\n",
    "plt.figure(figsize=(5, 5))\n",
    "sns.heatmap(pivot_table, cmap='coolwarm', annot=True, fmt=\".2f\", cbar_kws={'label': 'Probability of Left Choice'})\n",
    "plt.xlabel(\"Visual Stimulus Deviation\")\n",
    "plt.ylabel(\"Visual Stimulus Difference\")\n",
    "plt.title(\"Heatmap of Probability of Left Choice\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, instead of the difference, let's use the absolute value of the lowest visual stimulus\n",
    "# This is the absolute value of the lowest visual stimulus\n",
    "df_test['visual_stimulus_lowest'] = df_test['visual_stimulus'].apply(lambda x: abs(eval(x)[0]) if eval(x)[0] < eval(x)[1] else abs(eval(x)[1]))\n",
    "# create 10 bins for the absolute value of the lowest visual stimulus\n",
    "min_value = df_test['visual_stimulus_lowest'].min()\n",
    "max_value = df_test['visual_stimulus_lowest'].max()\n",
    "bins = np.linspace(min_value, max_value, 11)\n",
    "df_test['visual_stimulus_lowest_binned'] = pd.cut(df_test['visual_stimulus_lowest'], bins=bins, labels=[f\"{b:.2f}\" for b in bins[:-1]])\n",
    "# create a pivot table with the visual stimulus deviation and absolute value of the lowest visual stimulus\n",
    "pivot_table_abs = df_test.pivot_table(\n",
    "    index='visual_stimulus_lowest_binned',\n",
    "    columns='visual_stimulus_devi',\n",
    "    values='left_choice_new',\n",
    "    aggfunc='mean',\n",
    "    observed=True\n",
    ")\n",
    "# plot the heatmap\n",
    "plt.figure(figsize=(5, 5))\n",
    "sns.heatmap(pivot_table_abs, cmap='coolwarm', annot=True, fmt=\".2f\", cbar_kws={'label': 'Probability of Left Choice'})\n",
    "plt.xlabel(\"Visual Stimulus Deviation\")\n",
    "plt.ylabel(\"Absolute Value of Lowest Visual Stimulus\")\n",
    "plt.title(\"Heatmap of Probability of Left Choice\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Work on multiple animals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dic = {}\n",
    "for mouse in animals:\n",
    "    local_path = Path(utils.get_outpath()) / Path(tv_projects[1]) / Path(\"sessions\") / Path(mouse)\n",
    "    # create the directory if it doesn't exist\n",
    "    local_path.mkdir(parents=True, exist_ok=True)\n",
    "    # download the session data\n",
    "    utils.rsync_session_data(\n",
    "        project_name=tv_projects[1],\n",
    "        animal=mouse,\n",
    "        local_path=str(local_path),\n",
    "        credentials=utils.get_idibaps_cluster_credentials(),\n",
    "    )\n",
    "    # load the data\n",
    "    df_dic[mouse] = pd.read_csv(local_path / Path(f'{mouse}.csv'), sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dic_hard = {}\n",
    "for df_name, df in zip(df_dic.keys(), df_dic.values()):\n",
    "    if 'TwoAFC_visual_hard' in df[\"current_training_stage\"].unique():\n",
    "        df = df.dropna(subset = ['visual_stimulus'])\n",
    "        df = df[df[\"current_training_stage\"] == \"TwoAFC_visual_hard\"]\n",
    "\n",
    "        df['visual_stimulus_devi'] = df['visual_stimulus'].apply(lambda x: abs(round(eval(x)[0] / eval(x)[1], 4)))\n",
    "        df['visual_stimulus_devi'] = df.apply(\n",
    "            lambda row: row['visual_stimulus_devi'] if row['correct_side'] == 'left' else -row['visual_stimulus_devi'],\n",
    "            axis=1\n",
    "        )\n",
    "        df['visual_stimulus_diff'] = df['visual_stimulus'].apply(lambda x: abs(eval(x)[0] - eval(x)[1]))\n",
    "        df['visual_stimulus_diff'] = df.apply(\n",
    "            lambda row: row['visual_stimulus_diff'] if row['correct_side'] == 'left' else -row['visual_stimulus_diff'],\n",
    "            axis=1\n",
    "        )\n",
    "        df[\"visual_stimulus_diff_binned\"] = df['visual_stimulus_diff'] // 0.1\n",
    "        df = dft.add_mouse_first_choice(df)\n",
    "        df['left_choice_new'] = df['first_choice'].apply(lambda x: 1 if x == 'left' else 0)\n",
    "        \n",
    "        df_dic_hard[df_name] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_devi_diffBin_inter_p = pd.DataFrame()\n",
    "df_devi_diffBin_inter_coef = pd.DataFrame()\n",
    "for df_name, df in zip(df_dic_hard.keys(), df_dic_hard.values()):\n",
    "    df['interaction_term'] = df.apply(interaction_calc, axis=1)\n",
    "    # Prepare the independent variables\n",
    "    X_multi = df[['visual_stimulus_devi', 'visual_stimulus_diff_binned', 'interaction_term']]\n",
    "    X_multi_const = sm.add_constant(X_multi)\n",
    "    y = df['left_choice_new'].values.astype(int)\n",
    "\n",
    "    # Fit the logistic regression model with multiple regressors\n",
    "    logit_model_multi = sm.Logit(y, X_multi_const).fit()\n",
    "\n",
    "    df_devi_diffBin_inter_p[df_name] = logit_model_multi.pvalues\n",
    "    df_devi_diffBin_inter_coef[df_name] = logit_model_multi.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_devi_diff_inter_p = pd.DataFrame()\n",
    "df_devi_diff_inter_coef = pd.DataFrame()\n",
    "for df_name, df in zip(df_dic_hard.keys(), df_dic_hard.values()):\n",
    "    df['interaction_term'] = df.apply(interaction_calc, axis=1)\n",
    "    # Prepare the independent variables\n",
    "    X_multi = df[['visual_stimulus_devi', 'visual_stimulus_diff', 'interaction_term']]\n",
    "    X_multi_const = sm.add_constant(X_multi)\n",
    "    y = df['left_choice_new'].values.astype(int)\n",
    "\n",
    "    # Fit the logistic regression model with multiple regressors\n",
    "    logit_model_multi = sm.Logit(y, X_multi_const).fit()\n",
    "\n",
    "    df_devi_diff_inter_p[df_name] = logit_model_multi.pvalues\n",
    "    df_devi_diff_inter_coef[df_name] = logit_model_multi.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_devi_diffBin_inter_p.rename(index={'visual_stimulus_devi': 'devi', 'visual_stimulus_diff_binned': 'diff', 'interaction_term': 'inter'}, inplace=True)\n",
    "df_devi_diff_inter_p.rename(index={'visual_stimulus_devi': 'devi', 'visual_stimulus_diff': 'diff', 'interaction_term': 'inter'}, inplace=True)\n",
    "for df_name, color in zip(df_dic_hard.keys(), sns.color_palette(\"colorblind\", len(df_dic_hard))):\n",
    "    plt.plot (df_devi_diff_inter_p[df_name], label=df_name+ 'devi_diff_inter', color=color)\n",
    "    plt.plot (df_devi_diffBin_inter_p[df_name], label=df_name+ 'devi_diffBin_inter', color=color, linestyle='--')\n",
    "plt.axhline(y=0.05, color='k', linestyle='--', label='p-value threshold')\n",
    "plt.xlabel(\"Regressors\")\n",
    "plt.ylabel(\"p-value\")\n",
    "plt.legend(loc = (1 , 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_devi_diffBin_inter_coef.rename(index={'visual_stimulus_devi': 'devi', 'visual_stimulus_diff_binned': 'diff', 'interaction_term': 'inter'}, inplace=True)\n",
    "df_devi_diff_inter_coef.rename(index={'visual_stimulus_devi': 'devi', 'visual_stimulus_diff': 'diff', 'interaction_term': 'inter'}, inplace=True)\n",
    "for df_name, color in zip(df_dic_hard.keys(), sns.color_palette(\"colorblind\", len(df_dic_hard))):\n",
    "    plt.plot (df_devi_diff_inter_coef[df_name], label=df_name+ 'devi_diff_inter', color=color)\n",
    "    plt.plot (df_devi_diffBin_inter_coef[df_name], label=df_name+ 'devi_diffBin_inter', color=color, linestyle='--')\n",
    "plt.xlabel(\"Regressors\")\n",
    "plt.ylabel(\"Coefficient\")\n",
    "plt.legend(loc = (1 , 0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
